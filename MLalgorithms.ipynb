{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "import ember\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from features import PEFeatureExtractor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ember' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/elastic/ember.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_OF_THE_DATASET = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'c:\\Users\\jorge\\Desktop\\4 curso\\TFG\\Python-website\\ember\\install': [Errno 2] No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing ember.egg-info\\PKG-INFO\n",
      "writing dependency_links to ember.egg-info\\dependency_links.txt\n",
      "writing requirements to ember.egg-info\\requires.txt\n",
      "writing top-level names to ember.egg-info\\top_level.txt\n",
      "reading manifest file 'ember.egg-info\\SOURCES.txt'\n",
      "writing manifest file 'ember.egg-info\\SOURCES.txt'\n",
      "installing library code to build\\bdist.win-amd64\\egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\\bdist.win-amd64\\egg\n",
      "creating build\\bdist.win-amd64\\egg\\ember\n",
      "copying build\\lib\\ember\\features.py -> build\\bdist.win-amd64\\egg\\ember\n",
      "copying build\\lib\\ember\\__init__.py -> build\\bdist.win-amd64\\egg\\ember\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\ember\\features.py to features.cpython-39.pyc\n",
      "byte-compiling build\\bdist.win-amd64\\egg\\ember\\__init__.py to __init__.cpython-39.pyc\n",
      "creating build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying ember.egg-info\\PKG-INFO -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying ember.egg-info\\SOURCES.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying ember.egg-info\\dependency_links.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying ember.egg-info\\requires.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "copying ember.egg-info\\top_level.txt -> build\\bdist.win-amd64\\egg\\EGG-INFO\n",
      "creating 'dist\\ember-0.1.0-py3.9.egg' and adding 'build\\bdist.win-amd64\\egg' to it\n",
      "removing 'build\\bdist.win-amd64\\egg' (and everything under it)\n",
      "Processing ember-0.1.0-py3.9.egg\n",
      "Removing c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ember-0.1.0-py3.9.egg\n",
      "Copying ember-0.1.0-py3.9.egg to c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "ember 0.1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ember-0.1.0-py3.9.egg\n",
      "Processing dependencies for ember==0.1.0\n",
      "Searching for scikit-learn==1.0.2\n",
      "Best match: scikit-learn 1.0.2\n",
      "Adding scikit-learn 1.0.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for lightgbm==3.3.2\n",
      "Best match: lightgbm 3.3.2\n",
      "Adding lightgbm 3.3.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for pandas==1.4.2\n",
      "Best match: pandas 1.4.2\n",
      "Adding pandas 1.4.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for numpy==1.22.3\n",
      "Best match: numpy 1.22.3\n",
      "Adding numpy 1.22.3 to easy-install.pth file\n",
      "Installing f2py-script.py script to c:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\n",
      "Installing f2py.exe script to c:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for tqdm==4.64.0\n",
      "Best match: tqdm 4.64.0\n",
      "Adding tqdm 4.64.0 to easy-install.pth file\n",
      "Installing tqdm-script.py script to c:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\n",
      "Installing tqdm.exe script to c:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for lief==0.11.5\n",
      "Best match: lief 0.11.5\n",
      "Adding lief 0.11.5 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for scipy==1.8.0\n",
      "Best match: scipy 1.8.0\n",
      "Adding scipy 1.8.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for threadpoolctl==3.1.0\n",
      "Best match: threadpoolctl 3.1.0\n",
      "Adding threadpoolctl 3.1.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for joblib==1.1.0\n",
      "Best match: joblib 1.1.0\n",
      "Adding joblib 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for wheel==0.37.1\n",
      "Best match: wheel 0.37.1\n",
      "Adding wheel 0.37.1 to easy-install.pth file\n",
      "Installing wheel-script.py script to c:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\n",
      "Installing wheel.exe script to c:\\Users\\jorge\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for pytz==2022.1\n",
      "Best match: pytz 2022.1\n",
      "Adding pytz 2022.1 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for colorama==0.4.4\n",
      "Best match: colorama 0.4.4\n",
      "Adding colorama 0.4.4 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using c:\\users\\jorge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Finished processing dependencies for ember==0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zip_safe flag not set; analyzing archive contents...\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(CURRENT_PATH,\"ember\"))\n",
    "!python install -r requirements.txt\n",
    "!python setup.py install\n",
    "os.chdir(CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClassifier(classifier):\n",
    "    if classifier.lower() == \"randomforest\":\n",
    "        return RandomForestClassifier()\n",
    "    elif classifier.lower() == \"logisticregression\":\n",
    "        return LogisticRegression(max_iter=14000)\n",
    "    elif classifier.lower() == \"neuronalnetwork\":\n",
    "        return MLPClassifier(random_state=1, max_iter=100)\n",
    "    elif classifier.lower() == \"knearest\":\n",
    "        return KNeighborsClassifier(n_neighbors=5)\n",
    "    elif classifier.lower() == \"lineardiscriminant\":\n",
    "        return LinearDiscriminantAnalysis()\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndPredict(algorithm, X_train, y_train, X_test):\n",
    "    algorithm.fit(X_train, y_train)\n",
    "    predictions = algorithm.predict(X_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test, predictions):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(test,predictions)\n",
    "    plt.plot(fpr,tpr,'r-')\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(\"Roc Curve\")\n",
    "    plt.show()\n",
    "\n",
    "    #Matriz de confusion\n",
    "    conf_matrix=confusion_matrix(test,predictions)\n",
    "    ax = sns.heatmap(conf_matrix, annot=True, cmap='Reds')\n",
    "    ax.set_title('Confusion Matrix\\n\\n');\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(['False','True'])\n",
    "    ax.yaxis.set_ticklabels(['False','True'])\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()\n",
    "\n",
    "    #Precision del algoritmo\n",
    "    accuracyvalue=accuracy_score(test, predictions)\n",
    "    return accuracyvalue.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimedFiles(completeFile, trimedFile):\n",
    "    counter=0\n",
    "    unlabeledFiles='\"label\": -1'\n",
    "    new_file_test = open(trimedFile,\"w+\")\n",
    "    with open(completeFile) as test:\n",
    "        sample = heapq.nlargest(SIZE_OF_THE_DATASET*2, test, key=lambda L: random.random())\n",
    "        for item in sample:\n",
    "            if unlabeledFiles not in item:\n",
    "                new_file_test.write(item)\n",
    "                counter=counter+1\n",
    "            if counter==SIZE_OF_THE_DATASET:\n",
    "                break       \n",
    "    new_file_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictFile(model, file_data, feature_version=2):\n",
    "    extractor = PEFeatureExtractor(feature_version)\n",
    "    features = np.array(extractor.feature_vector(file_data), dtype=np.float32)\n",
    "    return model.predict([features])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictProbaFile(model, file_data, feature_version=2):\n",
    "    extractor = PEFeatureExtractor(feature_version)\n",
    "    features = np.array(extractor.feature_vector(file_data), dtype=np.float32)\n",
    "    return model.predict_proba([features])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportClassifier(classifier,fileToExport):\n",
    "    classifier_clone = joblib.dump(classifier, fileToExport, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathCompleteFiles = os.path.join(CURRENT_PATH,\"ember_dataset_2018_2\\\\ember2018\")\n",
    "pathTrimedFiles = os.path.join(CURRENT_PATH,\"ember_dataset_2018_2\\\\ember2018\\\\ember_trimed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started to trim files...\n",
      "Trim test file..\n",
      "Trim train 0 file..\n",
      "Trim train 1 file..\n",
      "Trim train 2 file..\n",
      "Trim train 3 file..\n",
      "Trim train 4 file..\n",
      "Trim train 5 file..\n",
      "Finished to trim files!\n"
     ]
    }
   ],
   "source": [
    "print(\"Started to trim files...\")\n",
    "\n",
    "print(\"Trim test file..\")\n",
    "trimedFiles(os.path.join(pathCompleteFiles,\"test_features.jsonl\"),\n",
    "os.path.join(pathTrimedFiles,\"test_features.jsonl\"))\n",
    "\n",
    "print(\"Trim train 0 file..\")\n",
    "trimedFiles(os.path.join(pathCompleteFiles,\"train_features_0.jsonl\"),\n",
    "os.path.join(pathTrimedFiles,\"train_features_0.jsonl\"))\n",
    "\n",
    "print(\"Trim train 1 file..\")\n",
    "trimedFiles(os.path.join(pathCompleteFiles,\"train_features_1.jsonl\"),\n",
    "os.path.join(pathTrimedFiles,\"train_features_1.jsonl\"))\n",
    "\n",
    "print(\"Trim train 2 file..\")\n",
    "trimedFiles(os.path.join(pathCompleteFiles,\"train_features_2.jsonl\"),\n",
    "os.path.join(pathTrimedFiles,\"train_features_2.jsonl\"))\n",
    "\n",
    "print(\"Trim train 3 file..\")\n",
    "trimedFiles(os.path.join(pathCompleteFiles,\"train_features_3.jsonl\"),\n",
    "os.path.join(pathTrimedFiles,\"train_features_3.jsonl\"))\n",
    "\n",
    "print(\"Trim train 4 file..\")\n",
    "trimedFiles(os.path.join(pathCompleteFiles,\"train_features_4.jsonl\"),\n",
    "os.path.join(pathTrimedFiles,\"train_features_4.jsonl\"))\n",
    "\n",
    "print(\"Trim train 5 file..\")\n",
    "trimedFiles(os.path.join(pathCompleteFiles,\"train_features_5.jsonl\"),\n",
    "os.path.join(pathTrimedFiles,\"train_features_5.jsonl\"))\n",
    "\n",
    "print(\"Finished to trim files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180000/180000 [05:44<00:00, 521.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:58<00:00, 512.68it/s]\n"
     ]
    }
   ],
   "source": [
    "ember.create_vectorized_features(pathTrimedFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(pathTrimedFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierLogisticReg = createClassifier(\"logisticRegression\")\n",
    "predictionsLogisticReg = trainAndPredict(classifierLogisticReg,X_train,y_train, X_test)\n",
    "accuracyLogisticReg=evaluate(y_test,predictionsLogisticReg)\n",
    "print(accuracyLogisticReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierNeuralNetwork = createClassifier(\"neuronalNetwork\")\n",
    "predictionsNeuralNetwork = trainAndPredict(classifierNeuralNetwork,X_train,y_train, X_test)\n",
    "accuracyNeuralNetwork=evaluate(y_test,predictionsNeuralNetwork)\n",
    "print(accuracyNeuralNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierKNearest = createClassifier(\"knearest\")\n",
    "predictionsKNearest = trainAndPredict(classifierKNearest,X_train,y_train, X_test)\n",
    "accuracyKNearest=evaluate(y_test,predictionsKNearest)\n",
    "print(accuracyKNearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierLinearDis = createClassifier(\"lineardiscriminant\")\n",
    "predictionsLinearDis = trainAndPredict(classifierLinearDis,X_train,y_train, X_test)\n",
    "accuracyLinearDis=evaluate(y_test,predictionsLinearDis)\n",
    "print(accuracyLinearDis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierRandomFor = createClassifier(\"randomForest\")\n",
    "predictionsRandomFor = trainAndPredict(classifierRandomFor,X_train,y_train, X_test)\n",
    "accuracyRandomFor=evaluate(y_test,predictionsRandomFor)\n",
    "print(accuracyRandomFor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliFile=os.path.join(CURRENT_PATH,\"ExeFiles\\\\cli.exe\")\n",
    "\n",
    "if predictFile(classifierRandomFor,cliFile)==0:\n",
    "    print(\"The \",cliFile,\" is a benign file\")\n",
    "else:\n",
    "    print(\"WARNING! The \",cliFile,\" is a malware file\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8df1771556d69f9aa81c7e5b9f82a1f88ce361bbedd71943be1c74c804727adb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
